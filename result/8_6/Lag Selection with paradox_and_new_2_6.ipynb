{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'feature_report.csv', 'sample_submission.csv', 'test.csv', 'test_leak_org.csv', 'test_leak_paradox.csv', 'test_leak_paradox_extend.csv', 'train.csv', 'train_leak_org.csv', 'train_leak_paradox.csv', 'train_leak_paradox_extend.csv']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "test = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "transact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\n",
    "y = np.log1p(train[\"target\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = train[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradox_cols = ['ced6a7e91', '9df4daa99', '83c3779bf', 'edc84139a', 'f1e0ada11', \n",
    "                '73687e512', 'aa164b93b', '342e7eb03', 'cd24eae8a', '8f3740670', \n",
    "                '2b2a10857', 'a00adf70e', '3a48a2cd2', 'a396ceeb9', '9280f3d04', \n",
    "                'fec5eaf1a', '5b943716b', '22ed6dba3', '5547d6e11', 'e222309b0', \n",
    "                '5d3b81ef8', '1184df5c2', '2288333b4', 'f39074b55', 'a8b721722', \n",
    "                '13ee58af1', 'fb387ea33', '4da206d28', 'ea4046b8d', 'ef30f6be5', \n",
    "                'b85fa8b27', '2155f5e16', '794e93ca6', '070f95c99', '939f628a7', \n",
    "                '7e814a30d', 'a6e871369', '0dc4d6c7d', 'bc70cbc26', 'aca228668']\n",
    "\n",
    "paradox_rows_name = ['a70090dc7','5b74875d4','ca6c4ea0d','242407fc6','7ff66b22b',\n",
    "                     'f43a48254','c9573f4ac','c14136677','08f544828','e77e32574',\n",
    "                     '61636fa41','4c0316d32','414871b56','2c518cd87','9eb93baef',\n",
    "                     'd63b2307d','db9ddeb12','7e45f5bd5','680ecfac8','814f58e7b',\n",
    "                     'eb850ef06','6edaf114d']\n",
    "\n",
    "paradox_rows = []\n",
    "for prn in paradox_rows_name:\n",
    "    paradox_rows.append(train[train.ID == prn].index[0])\n",
    "\n",
    "#tmp = train.loc[paradox_rows, [\"ID\",\"target\"] + paradox_cols]\n",
    "#print('shape', tmp.shape)\n",
    "#tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_last_1 = ['fec5644cf', 'caa9883f6', '9437d8b64', '68811ba58', 'ef4b87773',\n",
    "        'ff558c2f2', '8d918c64f', '0b8e10df6', '2d6565ce2', '0fe78acfa',\n",
    "        'b75aa754d', '2ab9356a0', '4e86dd8f3', '348aedc21', 'd7568383a',\n",
    "        '856856d94', '69900c0d1', '02c21443c', '5190d6dca', '20551fa5b',\n",
    "        '79cc300c7', '8d8276242', 'da22ed2b8', '89cebceab', 'f171b61af',\n",
    "        '3a07a8939', '129fe0263', 'e5b2d137a', 'aa7223176', '5ac7e84c4',\n",
    "        '9bd66acf6', '4c938629c', 'e62c5ac64', '57535b55a', 'a1a0084e3',\n",
    "        '2a3763e18', '474a9ec54', '0741f3757', '4fe8b17c2', 'd5754aa08']\n",
    "new_col_last_2 =['920a04ee2', '93efdb50f', '15ea45005', '78c57d7cd', '91570fb11',\n",
    "        'c5dacc85b', '145c7b018', '590b24ab1', 'c283d4609', 'e8bd579ae',\n",
    "        '7298ca1ef', 'ce53d1a35', 'a8f80f111', '2a9fed806', 'feb40ad9f',\n",
    "        'cfd255ee3', '31015eaab', '303572ae2', 'cd15bb515', 'cb5161856',\n",
    "        'a65b73c87', '71d64e3f7', 'ec5fb550f', '4af2493b6', '18b4fa3f5',\n",
    "        '3d655b0ed', '5cc9b6615', '88c0ec0a6', '8722f33bb', '5ed0c24d0',\n",
    "        '54f26ee08', '04ecdcbb3', 'ade8a5a19', 'd5efae759', 'ac7a97382',\n",
    "        'e1b20c3a6', 'b0fcfeab8', '438b8b599', '43782ef36', 'df69cf626']\n",
    "new_col_last_3 = ['5b465f819', 'a2aa0e4e9', '944e05d50', '4f8b27b6b', 'a498f253f',\n",
    "        'c73c31769', '025dea3b3', '616c01612', 'f3316966c', '83ea288de',\n",
    "        '2dbeac1de', '47b7b878f', 'b4d41b335', '686d60d8a', '6dcd9e752',\n",
    "        '7210546b2', '78edb3f13', '7f9d59cb3', '30992dccd', '26144d11f',\n",
    "        'a970277f9', '0aea1fd67', 'dc528471e', 'd51d10e38', 'efa99ed98',\n",
    "        '48420ad48', '7f38dafa6', '1af4ab267', '3a13ed79a', '73445227e',\n",
    "        '971631b2d', '57c4c03f6', '7f91dc936', '0784536d6', 'c3c3f66ff',\n",
    "        '052a76b0f', 'ffb34b926', '9d4f88c7b', '442b180b6', '948e00a8d']\n",
    "new_col_last_4 = ['c13ee1dc9', 'abb30bd35', 'd2919256b', '66728cc11', 'eab8abf7a',\n",
    "       'cc03b5217', '317ee395d', '38a92f707', '467c54d35', 'e8f065c9d',\n",
    "       '2ac62cba5', '6495d8c77', '94cdda53f', '13f2607e4', '1c047a8ce',\n",
    "       '28a5ad41a', '05cc08c11', 'b0cdc345e', '38f49406e', '773180cf6',\n",
    "       '1906a5c7e', 'c104aeb2e', '8e028d2d2', '0dc333fa1', '28a785c08',\n",
    "       '03ee30b8e', '8e5a41c43', '67102168f', '8b5c0fb4e', '14a22ab1a',\n",
    "       '9fc776466', '4aafb7383', '8e1dfcb94', '55741d46d', '8f940cb1b',\n",
    "       '758a9ab0e', 'fd812d7e0', '4ea447064', '6562e2a2c', '343922109']\n",
    "\n",
    "new_col_last_5 = ['8f6514df0', '6679fe54f', '5e62457b7', 'f17ff4efd', 'ec7f7017f',\n",
    "       'c02ab7d25', '8c309c553', 'e0b968d7b', '22b980fc8', '3b6b46221',\n",
    "       '3e4a6796d', 'c680e9350', '834fb292d', 'e3d33877c', '4052a9419',\n",
    "       'b95be4138', '16517c8b0', '219e051b5', 'a6fbe0987', '37d7af8ad',\n",
    "       'b84b2f72d', '775577e6f', '4f0c5f900', 'a68b83290', '2a2832b07',\n",
    "       'ce1f5b02a', 'a6c9347a7', '82c9b4fcd', '7f78a36f7', 'f49ff3269',\n",
    "       '89cffafe9', 'aeb3a6ccf', 'c7753cbfc', '4d6a1439e', '2123a4f36',\n",
    "       '5c56fccf1', '03bfe48b2', '6beb0b35d', '9fb38aabe', 'ae141696e']\n",
    "\n",
    "new_col_last_6 = ['266525925', '4b6dfc880', '2cff4bf0c', 'a3382e205', '6488c8200',\n",
    "       '547d3135b', 'b46191036', '453128993', '2599a7eb7', '2fc60d4d9',\n",
    "       '009319104', 'de14e7687', 'aa31dd768', '2b54cddfd', 'a67d02050',\n",
    "       '37aab1168', '939cc02f5', '31f72667c', '6f951302c', '54723be01',\n",
    "       '4681de4fd', '8bd53906a', '435f27009', 'f82167572', 'd428161d9',\n",
    "       '9015ac21d', 'ec4dc7883', '22c7b00ef', 'd4cc42c3d', '1351bf96e',\n",
    "       '1e8801477', 'b7d59d3b5', 'a459b5f7d', '580f5ff06', '39b3c553a',\n",
    "       '1eec37deb', '692c44993', 'ce8ce671e', '88ef1d9a8', 'bf042d928']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1',\n",
    "       '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9',\n",
    "       'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b', \n",
    "       '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212',  '66ace2992',\n",
    "       'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd', \n",
    "       '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n",
    "       '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2',  '0572565c2',\n",
    "       '190db8488',  'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extra_feats should be a list of feature lists\n",
    "\n",
    "\n",
    "def get_log_pred(data, feats, extra_feats, lag=0):\n",
    "    offset = lag + 2\n",
    "    f1 = feats[:(offset * -1)]\n",
    "    f2 = feats[offset:]\n",
    "    for ef in extra_feats:\n",
    "        f1 += ef[:(offset * -1)]\n",
    "        f2 += ef[offset:]\n",
    "    \n",
    "    d1 = data[f1].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2 = data[f2].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2['pred'] = data[feats[offset-2]]\n",
    "    d2 = d2[d2['pred'] != 0] # Keep?\n",
    "    d3 = d2[~d2.duplicated(['key'], keep=False)]\n",
    "    d4 = d1[~d1.duplicated(['key'], keep=False)]\n",
    "    d5 = d4.merge(d3, how='inner', on='key')\n",
    "    \n",
    "    d = d1.merge(d5, how='left', on='key')\n",
    "    return d.pred.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def _get_leak(df, cols, lag=0):\n",
    "#    d1 = df[cols[:-lag-2]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "#    d2 = df[cols[lag+2:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "#    d2['pred'] = df[cols[lag]]\n",
    "#    #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n",
    "#    d3 = d2[~d2.duplicated(['key'], keep=False)]\n",
    "#    return d1.merge(d3, how='left', on='key').pred.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compiled_leak_result():\n",
    "    \n",
    "    max_nlags = len(cols) - 2\n",
    "    extra_cols = paradox_cols + new_col_last_2 + new_col_last_3 + new_col_last_4 + new_col_last_5 \\\n",
    "                              + new_col_last_6\n",
    "       \n",
    "    extra_list = [paradox_cols, new_col_last_2, new_col_last_3, new_col_last_4, new_col_last_5,\n",
    "                                new_col_last_6]\n",
    "    \n",
    "    train_leak = train[[\"ID\", \"target\"] + cols + extra_cols]\n",
    "    train_leak[\"compiled_leak\"] = 0\n",
    "    train_leak[\"nonzero_mean\"] = train[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        train_leak[c] = get_log_pred(train_leak, cols, extra_list, i)\n",
    "        leaky_cols.append(c)\n",
    "        train_leak = train.join(\n",
    "            train_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )[[\"ID\", \"target\"] + cols + extra_cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]] ##changed \n",
    "        zeroleak = train_leak[\"compiled_leak\"]==0\n",
    "        train_leak.loc[zeroleak, \"compiled_leak\"] = train_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(train_leak[\"compiled_leak\"] > 0))\n",
    "        _correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in train\", leaky_value_counts[-1])\n",
    "        print(\n",
    "            \"% of correct leaks values in train \", \n",
    "            leaky_value_corrects[-1]\n",
    "        )\n",
    "        tmp = train_leak.copy()\n",
    "        tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n",
    "        scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        print(\n",
    "            'Score (filled with nonzero mean)', \n",
    "            scores[-1]\n",
    "        )\n",
    "    result = dict(\n",
    "        score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return train_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 0\n",
      "Leak values found in train 1376\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 1.5138333391635188\n",
      "Processing lag 1\n",
      "Leak values found in train 1986\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 1.2837324967824837\n",
      "Processing lag 2\n",
      "Leak values found in train 2376\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 1.158344347715661\n",
      "Processing lag 3\n",
      "Leak values found in train 2629\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 1.0599441159266052\n",
      "Processing lag 4\n",
      "Leak values found in train 2799\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 1.003768428505062\n",
      "Processing lag 5\n",
      "Leak values found in train 2948\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.9647709973956512\n",
      "Processing lag 6\n",
      "Leak values found in train 3070\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.9173110447464145\n",
      "Processing lag 7\n",
      "Leak values found in train 3169\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.8699402734318935\n",
      "Processing lag 8\n",
      "Leak values found in train 3254\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.8402918628067308\n",
      "Processing lag 9\n",
      "Leak values found in train 3307\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.8209746426425013\n",
      "Processing lag 10\n",
      "Leak values found in train 3368\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.8073540864812945\n",
      "Processing lag 11\n",
      "Leak values found in train 3410\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.7925868209638435\n",
      "Processing lag 12\n",
      "Leak values found in train 3454\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.775792963609613\n",
      "Processing lag 13\n",
      "Leak values found in train 3495\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.7622923431297832\n",
      "Processing lag 14\n",
      "Leak values found in train 3529\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.74747722227444\n",
      "Processing lag 15\n",
      "Leak values found in train 3556\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.7346015338062746\n",
      "Processing lag 16\n",
      "Leak values found in train 3575\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.7255997590630155\n",
      "Processing lag 17\n",
      "Leak values found in train 3597\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.717353293741664\n",
      "Processing lag 18\n",
      "Leak values found in train 3615\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.7098070964809714\n",
      "Processing lag 19\n",
      "Leak values found in train 3633\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.7029183269360878\n",
      "Processing lag 20\n",
      "Leak values found in train 3647\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6932611983090249\n",
      "Processing lag 21\n",
      "Leak values found in train 3664\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6830482670340141\n",
      "Processing lag 22\n",
      "Leak values found in train 3678\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6738051460475788\n",
      "Processing lag 23\n",
      "Leak values found in train 3695\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6697259422128963\n",
      "Processing lag 24\n",
      "Leak values found in train 3705\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6629070823682318\n",
      "Processing lag 25\n",
      "Leak values found in train 3712\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6617726461554991\n",
      "Processing lag 26\n",
      "Leak values found in train 3721\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6595984027178762\n",
      "Processing lag 27\n",
      "Leak values found in train 3726\n",
      "% of correct leaks values in train  1.0\n",
      "Score (filled with nonzero mean) 0.6568068625261366\n",
      "Processing lag 28\n",
      "Leak values found in train 3733\n",
      "% of correct leaks values in train  0.999732118939191\n",
      "Score (filled with nonzero mean) 0.6548488539443967\n",
      "Processing lag 29\n",
      "Leak values found in train 3738\n",
      "% of correct leaks values in train  0.9997324772605671\n",
      "Score (filled with nonzero mean) 0.653007722436817\n",
      "Processing lag 30\n",
      "Leak values found in train 3741\n",
      "% of correct leaks values in train  0.9997326917936381\n",
      "Score (filled with nonzero mean) 0.6504685654024377\n",
      "Processing lag 31\n",
      "Leak values found in train 3742\n",
      "% of correct leaks values in train  0.9997327632282202\n",
      "Score (filled with nonzero mean) 0.6493281499481802\n",
      "Processing lag 32\n",
      "Leak values found in train 3745\n",
      "% of correct leaks values in train  0.9997329773030708\n",
      "Score (filled with nonzero mean) 0.6491111192584899\n",
      "Processing lag 33\n",
      "Leak values found in train 3749\n",
      "% of correct leaks values in train  0.9997332622032542\n",
      "Score (filled with nonzero mean) 0.6481645697708703\n",
      "Processing lag 34\n",
      "Leak values found in train 3752\n",
      "% of correct leaks values in train  0.9997334754797441\n",
      "Score (filled with nonzero mean) 0.6470365302766748\n",
      "Processing lag 35\n",
      "Leak values found in train 3754\n",
      "% of correct leaks values in train  0.9997336174746937\n",
      "Score (filled with nonzero mean) 0.6465723989938899\n",
      "Processing lag 36\n",
      "Leak values found in train 3754\n",
      "% of correct leaks values in train  0.9997336174746937\n",
      "Score (filled with nonzero mean) 0.6442714994927643\n",
      "Processing lag 37\n",
      "Leak values found in train 3754\n",
      "% of correct leaks values in train  0.9997336174746937\n",
      "Score (filled with nonzero mean) 0.6442714994927643\n"
     ]
    }
   ],
   "source": [
    "train_leak, result = compiled_leak_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score 0.6442714994927643 \n",
      "best_lag 36\n"
     ]
    }
   ],
   "source": [
    "best_score = np.min(result['score'])\n",
    "best_lag = np.argmin(result['score'])\n",
    "print('best_score', best_score, '\\nbest_lag', best_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_compiled_leak(leak_df, lag):\n",
    "    leak_df[\"compiled_leak\"] = 0\n",
    "    for i in range(lag):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        zeroleak = leak_df[\"compiled_leak\"]==0\n",
    "        leak_df.loc[zeroleak, \"compiled_leak\"] = leak_df.loc[zeroleak, c]\n",
    "    return leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_cols = [c for c in train_leak.columns if 'leaked_target_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>leaked_target_0</th>\n",
       "      <th>leaked_target_1</th>\n",
       "      <th>leaked_target_2</th>\n",
       "      <th>leaked_target_3</th>\n",
       "      <th>leaked_target_4</th>\n",
       "      <th>leaked_target_5</th>\n",
       "      <th>leaked_target_6</th>\n",
       "      <th>leaked_target_7</th>\n",
       "      <th>leaked_target_8</th>\n",
       "      <th>...</th>\n",
       "      <th>leaked_target_29</th>\n",
       "      <th>leaked_target_30</th>\n",
       "      <th>leaked_target_31</th>\n",
       "      <th>leaked_target_32</th>\n",
       "      <th>leaked_target_33</th>\n",
       "      <th>leaked_target_34</th>\n",
       "      <th>leaked_target_35</th>\n",
       "      <th>leaked_target_36</th>\n",
       "      <th>leaked_target_37</th>\n",
       "      <th>compiled_leak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  leaked_target_0  leaked_target_1  leaked_target_2  \\\n",
       "0  000d6aaf2       38000000.0       38000000.0       38000000.0   \n",
       "1  000fbd867         600000.0              0.0              0.0   \n",
       "2  0027d6b71              0.0              0.0              0.0   \n",
       "3  0028cbf45              0.0              0.0              0.0   \n",
       "4  002a68644              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_3  leaked_target_4  leaked_target_5  leaked_target_6  \\\n",
       "0              0.0       38000000.0              0.0       38000000.0   \n",
       "1              0.0              0.0              0.0         600000.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3        2000000.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_7  leaked_target_8      ...        leaked_target_29  \\\n",
       "0              0.0              0.0      ...              38000000.0   \n",
       "1              0.0         600000.0      ...                     0.0   \n",
       "2              0.0              0.0      ...                     0.0   \n",
       "3              0.0              0.0      ...                     0.0   \n",
       "4              0.0              0.0      ...                     0.0   \n",
       "\n",
       "   leaked_target_30  leaked_target_31  leaked_target_32  leaked_target_33  \\\n",
       "0               0.0        38000000.0               0.0        38000000.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   leaked_target_34  leaked_target_35  leaked_target_36  leaked_target_37  \\\n",
       "0        38000000.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   compiled_leak  \n",
       "0     38000000.0  \n",
       "1       600000.0  \n",
       "2            0.0  \n",
       "3      2000000.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_leak = rewrite_compiled_leak(train_leak, best_lag+1)\n",
    "train_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = train_leak[[\"ID\"]+leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "train_res.to_csv('train_leak_paradox_and_newlast_2_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compiled_leak_result_test(max_nlags):\n",
    "    extra_cols = paradox_cols + new_col_last_2 + new_col_last_3 + new_col_last_4 + new_col_last_5 \\\n",
    "                              + new_col_last_6\n",
    "       \n",
    "    extra_list = [paradox_cols, new_col_last_2, new_col_last_3, new_col_last_4, new_col_last_5,\n",
    "                                new_col_last_6]    \n",
    "    \n",
    "    test_leak = test[[\"ID\", \"target\"] + cols + extra_cols]\n",
    "    test_leak[\"compiled_leak\"] = 0\n",
    "    test_leak[\"nonzero_mean\"] = test[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    # leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        #test_leak[c] = _get_leak(test_leak, cols, i)\n",
    "        \n",
    "        test_leak[c] = get_log_pred(test_leak, cols, extra_list, i)\n",
    "        leaky_cols.append(c)\n",
    "        test_leak = test.join(\n",
    "            test_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )[[\"ID\", \"target\"] + cols + extra_cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]  #changed\n",
    "        zeroleak = test_leak[\"compiled_leak\"]==0\n",
    "        test_leak.loc[zeroleak, \"compiled_leak\"] = test_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(test_leak[\"compiled_leak\"] > 0))\n",
    "        #_correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        #leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in test\", leaky_value_counts[-1])\n",
    "        #print(\n",
    "        #    \"% of correct leaks values in train \", \n",
    "        #    leaky_value_corrects[-1]\n",
    "        #)\n",
    "        #tmp = train_leak.copy()\n",
    "        #tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n",
    "        #scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        #print(\n",
    "        #    'Score (filled with nonzero mean)', \n",
    "        #    scores[-1]\n",
    "        #)\n",
    "    result = dict(\n",
    "        # score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        # leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return test_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 0\n",
      "Leak values found in test 2957\n",
      "Processing lag 1\n",
      "Leak values found in test 4216\n",
      "Processing lag 2\n",
      "Leak values found in test 4965\n",
      "Processing lag 3\n",
      "Leak values found in test 5526\n",
      "Processing lag 4\n",
      "Leak values found in test 5943\n",
      "Processing lag 5\n",
      "Leak values found in test 6233\n",
      "Processing lag 6\n",
      "Leak values found in test 6437\n",
      "Processing lag 7\n",
      "Leak values found in test 6586\n",
      "Processing lag 8\n",
      "Leak values found in test 6749\n",
      "Processing lag 9\n",
      "Leak values found in test 6882\n",
      "Processing lag 10\n",
      "Leak values found in test 6993\n",
      "Processing lag 11\n",
      "Leak values found in test 7088\n",
      "Processing lag 12\n",
      "Leak values found in test 7161\n",
      "Processing lag 13\n",
      "Leak values found in test 7239\n",
      "Processing lag 14\n",
      "Leak values found in test 7296\n",
      "Processing lag 15\n",
      "Leak values found in test 7354\n",
      "Processing lag 16\n",
      "Leak values found in test 7400\n",
      "Processing lag 17\n",
      "Leak values found in test 7441\n",
      "Processing lag 18\n",
      "Leak values found in test 7471\n",
      "Processing lag 19\n",
      "Leak values found in test 7511\n",
      "Processing lag 20\n",
      "Leak values found in test 7545\n",
      "Processing lag 21\n",
      "Leak values found in test 7576\n",
      "Processing lag 22\n",
      "Leak values found in test 7609\n",
      "Processing lag 23\n",
      "Leak values found in test 7630\n",
      "Processing lag 24\n",
      "Leak values found in test 7652\n",
      "Processing lag 25\n",
      "Leak values found in test 7668\n",
      "Processing lag 26\n",
      "Leak values found in test 7683\n",
      "Processing lag 27\n",
      "Leak values found in test 7695\n",
      "Processing lag 28\n",
      "Leak values found in test 7715\n",
      "Processing lag 29\n",
      "Leak values found in test 7737\n",
      "Processing lag 30\n",
      "Leak values found in test 7757\n",
      "Processing lag 31\n",
      "Leak values found in test 7788\n",
      "Processing lag 32\n",
      "Leak values found in test 7813\n",
      "Processing lag 33\n",
      "Leak values found in test 7843\n",
      "Processing lag 34\n",
      "Leak values found in test 7890\n",
      "Processing lag 35\n",
      "Leak values found in test 7947\n",
      "Processing lag 36\n",
      "Leak values found in test 8029\n",
      "Processing lag 37\n",
      "Leak values found in test 8118\n"
     ]
    }
   ],
   "source": [
    "test_leak, test_result = compiled_leak_result_test(max_nlags=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leaky_count</th>\n",
       "      <td>2957</td>\n",
       "      <td>4216</td>\n",
       "      <td>4965</td>\n",
       "      <td>5526</td>\n",
       "      <td>5943</td>\n",
       "      <td>6233</td>\n",
       "      <td>6437</td>\n",
       "      <td>6586</td>\n",
       "      <td>6749</td>\n",
       "      <td>6882</td>\n",
       "      <td>...</td>\n",
       "      <td>7715</td>\n",
       "      <td>7737</td>\n",
       "      <td>7757</td>\n",
       "      <td>7788</td>\n",
       "      <td>7813</td>\n",
       "      <td>7843</td>\n",
       "      <td>7890</td>\n",
       "      <td>7947</td>\n",
       "      <td>8029</td>\n",
       "      <td>8118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9   ...   \\\n",
       "leaky_count  2957  4216  4965  5526  5943  6233  6437  6586  6749  6882  ...    \n",
       "\n",
       "               28    29    30    31    32    33    34    35    36    37  \n",
       "leaky_count  7715  7737  7757  7788  7813  7843  7890  7947  8029  8118  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.DataFrame.from_dict(test_result, orient='columns')\n",
    "test_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>leaked_target_0</th>\n",
       "      <th>leaked_target_1</th>\n",
       "      <th>leaked_target_2</th>\n",
       "      <th>leaked_target_3</th>\n",
       "      <th>leaked_target_4</th>\n",
       "      <th>leaked_target_5</th>\n",
       "      <th>leaked_target_6</th>\n",
       "      <th>leaked_target_7</th>\n",
       "      <th>leaked_target_8</th>\n",
       "      <th>...</th>\n",
       "      <th>leaked_target_29</th>\n",
       "      <th>leaked_target_30</th>\n",
       "      <th>leaked_target_31</th>\n",
       "      <th>leaked_target_32</th>\n",
       "      <th>leaked_target_33</th>\n",
       "      <th>leaked_target_34</th>\n",
       "      <th>leaked_target_35</th>\n",
       "      <th>leaked_target_36</th>\n",
       "      <th>leaked_target_37</th>\n",
       "      <th>compiled_leak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  leaked_target_0  leaked_target_1  leaked_target_2  \\\n",
       "0  000137c73              0.0              0.0              0.0   \n",
       "1  00021489f              0.0              0.0              0.0   \n",
       "2  0004d7953              0.0              0.0              0.0   \n",
       "3  00056a333              0.0              0.0              0.0   \n",
       "4  00056d8eb              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_3  leaked_target_4  leaked_target_5  leaked_target_6  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_7  leaked_target_8      ...        leaked_target_29  \\\n",
       "0              0.0              0.0      ...                     0.0   \n",
       "1              0.0              0.0      ...                     0.0   \n",
       "2              0.0              0.0      ...                     0.0   \n",
       "3              0.0              0.0      ...                     0.0   \n",
       "4              0.0              0.0      ...                     0.0   \n",
       "\n",
       "   leaked_target_30  leaked_target_31  leaked_target_32  leaked_target_33  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   leaked_target_34  leaked_target_35  leaked_target_36  leaked_target_37  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   compiled_leak  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_leak = rewrite_compiled_leak(test_leak, best_lag+1)\n",
    "test_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = test_leak[[\"ID\"]+leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "test_res.to_csv('test_leak_paradox_and_newlast_2_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leak.loc[test_leak[\"compiled_leak\"]==0, \"compiled_leak\"] = test_leak.loc[test_leak[\"compiled_leak\"]==0, \"nonzero_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[[\"ID\"]]\n",
    "sub[\"target\"] = test_leak[\"compiled_leak\"]\n",
    "sub.to_csv(f\"baseline_sub_lag_{best_lag}.csv\", index=False)\n",
    "print(f\"baseline_sub_lag_{best_lag}.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paradox's col\n",
    "#ordered_cols = ['ced6a7e91','9df4daa99','83c3779bf','edc84139a','f1e0ada11',\n",
    "#                '73687e512','aa164b93b','342e7eb03','cd24eae8a','8f3740670',\n",
    "#                '2b2a10857','a00adf70e','3a48a2cd2','a396ceeb9','9280f3d04',\n",
    "#                'fec5eaf1a','5b943716b','22ed6dba3','5547d6e11','e222309b0',\n",
    "#                '5d3b81ef8','1184df5c2','2288333b4','f39074b55','a8b721722',\n",
    "#                '13ee58af1','fb387ea33','4da206d28','ea4046b8d','ef30f6be5',\n",
    "#                'b85fa8b27','2155f5e16']\n",
    "#\n",
    "#ordered_ids = ['a70090dc7','5b74875d4','ca6c4ea0d','242407fc6','7ff66b22b',\n",
    "#               'f43a48254','c9573f4ac','c14136677','08f544828','e77e32574',\n",
    "#               '61636fa41','4c0316d32','414871b56','2c518cd87','9eb93baef',\n",
    "#               'd63b2307d','db9ddeb12','7e45f5bd5','680ecfac8','814f58e7b',\n",
    "#               'eb850ef06','6edaf114d']\n",
    "#\n",
    "#ordered_indexes = []\n",
    "#for oi in ordered_ids:\n",
    "#    ordered_indexes.append(train[train.ID == oi].index[0])\n",
    "#\n",
    "#tmp = train.loc[ordered_indexes, [\"ID\",\"target\"] + ordered_cols]\n",
    "#print('shape', tmp.shape)\n",
    "#tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
