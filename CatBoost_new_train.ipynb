{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'baseline_sub_lag_25_all_df.csv', 'baseline_sub_lag_29_non_zero.csv', 'baseline_sub_lag_29_zerokill.csv', 'feature_report.csv', 'new_train_0808.csv', 'new_train_081415_111sets.csv', 'sample_submission.csv', 'test.csv', 'test_for_train.csv', 'test_leak_081204_7880.csv', 'test_leak_081316_7856.csv', 'test_leak_081415_7854_111sets.csv', 'test_leak_org.csv', 'test_leak_paradox.csv', 'test_leak_paradox_and_new_1.csv', 'test_leak_paradox_and_new_and_extreme.csv', 'test_leak_paradox_and_newlast_2_6.csv', 'test_leak_paradox_and_newlast_v8_6new.csv', 'test_leak_paradox_extend.csv', 'total.csv', 'total.csv.zip', 'train.csv', 'train_leak_081204_3886.csv', 'train_leak_081316_all.csv', 'train_leak_081415_111sets.csv', 'train_leak_org.csv', 'train_leak_paradox.csv', 'train_leak_paradox_and_new_1.csv', 'train_leak_paradox_and_new_and_extreme.csv', 'train_leak_paradox_and_newlast_2_6.csv', 'train_leak_paradox_and_newlast_v8_6new.csv', 'train_leak_paradox_extend.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "test = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "transact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_leak = pd.read_csv(\"./input/train_leak_081415_111sets.csv\")\n",
    "test_leak = pd.read_csv(\"./input/test_leak_081415_7854_111sets.csv\")\n",
    "train_leak = train_leak.replace(np.nan,0.0)\n",
    "test_leak = test_leak.replace(np.nan,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_compiled_leak(leak_df, lag):\n",
    "    leak_df[\"compiled_leak\"] = 0\n",
    "    for i in range(lag):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        zeroleak = leak_df[\"compiled_leak\"]==0\n",
    "        leak_df.loc[zeroleak, \"compiled_leak\"] = leak_df.loc[zeroleak, c]\n",
    "    return leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_cols = [c for c in train_leak.columns if 'leaked_target_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>leaked_target_0</th>\n",
       "      <th>leaked_target_1</th>\n",
       "      <th>leaked_target_2</th>\n",
       "      <th>leaked_target_3</th>\n",
       "      <th>leaked_target_4</th>\n",
       "      <th>leaked_target_5</th>\n",
       "      <th>leaked_target_6</th>\n",
       "      <th>leaked_target_7</th>\n",
       "      <th>leaked_target_8</th>\n",
       "      <th>...</th>\n",
       "      <th>leaked_target_29</th>\n",
       "      <th>leaked_target_30</th>\n",
       "      <th>leaked_target_31</th>\n",
       "      <th>leaked_target_32</th>\n",
       "      <th>leaked_target_33</th>\n",
       "      <th>leaked_target_34</th>\n",
       "      <th>leaked_target_35</th>\n",
       "      <th>leaked_target_36</th>\n",
       "      <th>leaked_target_37</th>\n",
       "      <th>compiled_leak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  leaked_target_0  leaked_target_1  leaked_target_2  \\\n",
       "0  000d6aaf2       38000000.0       38000000.0       38000000.0   \n",
       "1  000fbd867         600000.0              0.0              0.0   \n",
       "2  0027d6b71              0.0              0.0              0.0   \n",
       "3  0028cbf45              0.0              0.0              0.0   \n",
       "4  002a68644              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_3  leaked_target_4  leaked_target_5  leaked_target_6  \\\n",
       "0              0.0       38000000.0              0.0       38000000.0   \n",
       "1              0.0              0.0              0.0         600000.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3        2000000.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_7  leaked_target_8      ...        leaked_target_29  \\\n",
       "0              0.0              0.0      ...              38000000.0   \n",
       "1              0.0         600000.0      ...                     0.0   \n",
       "2              0.0              0.0      ...                     0.0   \n",
       "3              0.0              0.0      ...                     0.0   \n",
       "4              0.0              0.0      ...                     0.0   \n",
       "\n",
       "   leaked_target_30  leaked_target_31  leaked_target_32  leaked_target_33  \\\n",
       "0               0.0        38000000.0               0.0        38000000.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0         2000000.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   leaked_target_34  leaked_target_35  leaked_target_36  leaked_target_37  \\\n",
       "0        38000000.0               0.0               0.0        38000000.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   compiled_leak  \n",
       "0     38000000.0  \n",
       "1       600000.0  \n",
       "2            0.0  \n",
       "3      2000000.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lag = 37\n",
    "train_leak = rewrite_compiled_leak(train_leak, best_lag)\n",
    "test_leak = rewrite_compiled_leak(test_leak, best_lag)\n",
    "train_leak.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = test.loc[test_leak[\"compiled_leak\"] > 0].copy()\n",
    "new_train[\"target\"] = test_leak[\"compiled_leak\"].loc[test_leak[\"compiled_leak\"] > 0]\n",
    "new_train[\"leak\"] = new_train[\"target\"]\n",
    "new_train['log_leak'] = np.log1p(new_train[\"leak\"])\n",
    "\n",
    "_temp_train = train.copy()\n",
    "_temp_train[\"leak\"] = train_leak['compiled_leak']\n",
    "_temp_train['log_leak'] = np.log1p(_temp_train[\"leak\"])\n",
    "\n",
    "new_train = pd.concat([_temp_train, new_train]).reset_index(drop=True)\n",
    "new_test = test.loc[test_leak[\"compiled_leak\"] == 0].copy().reset_index(drop=True)\n",
    "new_test['leak'] = 0\n",
    "new_test['log_leak'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train.to_csv(\"new_train_081415_111sets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(new_train['target'])\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "features = [f for f in new_train if f not in ['ID', 'leak', 'log_leak', 'target']]\n",
    "\n",
    "new_train.replace(0, np.nan, inplace=True)\n",
    "new_train['log_of_mean'] = np.log1p(new_train[features].replace(0, np.nan).mean(axis=1))\n",
    "new_train['mean_of_log'] = np.log1p(new_train[features]).replace(0, np.nan).mean(axis=1)\n",
    "new_train['log_of_median'] = np.log1p(new_train[features][features].replace(0, np.nan).median(axis=1))\n",
    "new_train['nb_nans'] = new_train[features].isnull().sum(axis=1)\n",
    "new_train['the_sum'] = np.log1p(new_train[features].sum(axis=1))\n",
    "new_train['the_std'] = new_train[features].std(axis=1)\n",
    "new_train['the_kur'] = new_train[features].kurtosis(axis=1)\n",
    "\n",
    "new_test.replace(0, np.nan, inplace=True)\n",
    "new_test['log_of_mean'] = np.log1p(new_test[features].replace(0, np.nan).mean(axis=1))\n",
    "new_test['mean_of_log'] = np.log1p(new_test[features]).replace(0, np.nan).mean(axis=1)\n",
    "new_test['log_of_median'] = np.log1p(new_test[features].replace(0, np.nan).median(axis=1))\n",
    "new_test['nb_nans'] = new_test[features].isnull().sum(axis=1)\n",
    "new_test['the_sum'] = np.log1p(new_test[features].sum(axis=1))\n",
    "new_test['the_std'] = new_test[features].std(axis=1)\n",
    "new_test['the_kur'] = new_test[features].kurtosis(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_criterion = 0.7907\n",
    "report = pd.read_csv(\"./input/feature_report.csv\")\n",
    "good_features = report.loc[report['rmse'] <= feature_criterion][\"feature\"].values\n",
    "features = good_features.tolist()\n",
    "features = features + ['log_leak', 'log_of_mean', 'mean_of_log', 'log_of_median', 'nb_nans', 'the_sum', 'the_std', 'the_kur']\n",
    "\n",
    "cat_train = new_train[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5706684809794174\n",
      "0.5566110400904399\n",
      "0.574616006388636\n",
      "0.5670554602752552\n",
      "0.5650717826700655\n",
      "OOF SCORE :  0.750048\n",
      "OOF SCORE with LEAK :  0.632932\n",
      "CPU times: user 10min 19s, sys: 1min 55s, total: 12min 14s\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_test['target'] = 0\n",
    "oof_preds = np.zeros(new_train.shape[0])\n",
    "for trn_idx, val_idx in folds.split(new_train):\n",
    "    train_pool = Pool(cat_train.iloc[trn_idx], target.iloc[trn_idx])\n",
    "    valid_pool = Pool(cat_train.iloc[val_idx], target.iloc[val_idx])\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=200,\n",
    "                              learning_rate=0.05,\n",
    "                              depth=12,\n",
    "                              reg_lambda = 0.27039842736589326,\n",
    "                              bootstrap_type = \"Bayesian\",\n",
    "                              bagging_temperature = 0.2,\n",
    "                              od_type='Iter',\n",
    "                              od_wait=20,\n",
    "                              random_seed = 3,\n",
    "                              eval_metric='RMSE',\n",
    "                              verbose = 2)\n",
    "\n",
    "    model.fit(train_pool, eval_set=valid_pool, use_best_model=True, verbose=False)\n",
    "    oof_preds[val_idx] = model.predict(cat_train.iloc[val_idx])\n",
    "    \n",
    "    new_test['target'] += model.predict(new_test[features]) / folds.n_splits\n",
    "    print(mean_squared_error(target.iloc[val_idx], \n",
    "                             oof_preds[val_idx]) ** .5)\n",
    "    \n",
    "new_train['predictions'] = oof_preds\n",
    "new_train.loc[new_train['leak'].notnull(), 'predictions'] = np.log1p(new_train.loc[new_train['leak'].notnull(), 'leak'])\n",
    "print('OOF SCORE : %9.6f' \n",
    "      % (mean_squared_error(target[:len(train)], oof_preds[:len(train)]) ** .5)) #[:len(train)]\n",
    "print('OOF SCORE with LEAK : %9.6f' \n",
    "      % (mean_squared_error(target[:len(train)], new_train['predictions'][:len(train)]) ** .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test['target'] = np.expm1(new_test['target'])\n",
    "new_test.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = test[[\"ID\"]]\n",
    "#sub[\"target\"] = test_leak[\"compiled_leak\"]\n",
    "#sub.loc[sub[\"target\"] > 0, \"target\"] = np.expm1(oof_preds[len(train):])\n",
    "#sub.loc[sub[\"target\"] == 0, \"target\"] = new_test['target'].values\n",
    "#sub.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[[\"ID\"]]\n",
    "sub[\"target\"] = test_leak[\"compiled_leak\"]\n",
    "sub.loc[sub[\"target\"] == 0, \"target\"] = new_test['target'].values\n",
    "sub.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f\"lgb_new_train_{best_lag}.csv\", index=False)\n",
    "print(f\"lgb_new_train_{best_lag}.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_res = train_leak[[\"ID\"]+leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "#train_res.to_csv('train_leak.csv', index=False)\n",
    "#print(f\"train_leak.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_res = test_leak[[\"ID\"]+leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "#test_res.to_csv('test_leak.csv', index=False)\n",
    "#print(f\"test_leak.csv saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
